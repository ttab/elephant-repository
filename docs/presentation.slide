# Elephant

Internal 2023-03-07, updated 2026-02-27

Hugo Wetterberg
hugo.wetterberg@tt.se

## The repository

The repository is a Go application that exposes a Twirp RPC API.

* Code generation for
  * RPC interfaces and types (from protobuf)
  * SQL queries (from schema and queries)

## Running and scaling the Elephant

Except some cached configuration (validation schemas, statuses, et.c.) the service is completely stateless.

* Small footprint
* Redundancy will probably be main reason for running multiple instances
* An instance can run with certain components disabled
  * A dedicated API front instance could run with `--no-archiver --no-eventlog-builder --no-eventsink --no-scheduler`

Where it's necessary to coordinate between instances it's handled by Postgres row locks or advisory locks.

Aims to keep the number of runtime dependencies to a minimum. As long as it gets a Postgres instance and an S3 compatible object store it should "just work".

## The data

Elephant stores:

* documents
* statuses
* ACLs (access control lists)
* document schemas
* metrics
* archive signing keys

All writes go through Postgres so that we get strong consistency guarantees.

A background process called the Archiver continually archives document and status data in S3.

## Immutability

Document versions and statuses are treated as immutable.

Some flags like archived status and signature can be updated, but the actual contents and metadata cannot be changed through the API.

The archiver uses this fact to calculate a signature chain where the entire history of a document can be cryptographically verified.

## The API

The API is defined in a protobuf file.

Elephant exposes four services:

* Documents - for document CRUD operations, eventlog, locking, assets, and WebSocket tokens
* Schemas - for managing Revisor schemas, document types, and meta types
* Workflows - for managing statuses, status rules, and workflow definitions
* Metrics - for defining and tracking custom metrics

Clients can communicate with these services using JSON or protobuf.

* Generate Twirp clients
* Generate OpenAPI client
* ...or make your own bespoke calls.

## Current permission scopes

* Document CRUD: `doc_read`, `doc_write`, `doc_delete`, `doc_admin`
  * The doc scopes work together with the document ACLs.
  * Both scope and an ACL granting permission are required.
* `doc_read_all` bypasses ACLs for read access.
* `doc_import` allows the caller to override timestamps and the user sub for Update requests.
* `doc_restore` and `doc_purge` for deletion lifecycle management.
* `meta_doc_write_all` allows writing to all document metadata.
* `asset_upload` allows uploading assets and attachments.
* `eventlog_read` gives access to the eventlog and WebSocket eventlog streaming.
* `workflow_admin` gives access to the `Workflows` service.
* `schema_read` and `schema_admin` for the `Schemas` service.
* `metrics_read`, `metrics_write`, and `metrics_admin` for the `Metrics` service.

Per-document ACL entries can grant: Read, Write, MetaWrite, and SetStatus permissions.

## The API - Documents

An extract of the Documents API:

```
service Documents {
  // Get retrieves a document version.
  rpc Get(GetDocumentRequest) returns (GetDocumentResponse);

  // BulkGet retrieves multiple documents with optional subset extraction.
  rpc BulkGet(BulkGetRequest) returns (BulkGetResponse);

  // GetHistory lists the document version history.
  rpc GetHistory(GetHistoryRequest) returns (GetHistoryResponse);

  // Update is used to create new document versions, set statuses, update ACLs.
  rpc Update(UpdateRequest) returns (UpdateResponse);

  // BulkUpdate performs batch updates of multiple documents.
  rpc BulkUpdate(BulkUpdateRequest) returns (BulkUpdateResponse);

  // Validate is used to validate a document without writing it to the
  // repository.
  rpc Validate(ValidateRequest) returns (ValidateResponse);

  // Delete deletes a document and all its associated data.
  rpc Delete(DeleteDocumentRequest) returns (DeleteDocumentResponse);

  // Restore restores a previously deleted document.
  rpc Restore(RestoreRequest) returns (RestoreResponse);

  // Purge permanently removes archived data for a deleted document.
  rpc Purge(PurgeRequest) returns (PurgeResponse);

  // GetMeta returns metadata for a document, including the ACL and current
  // status heads.
  rpc GetMeta(GetMetaRequest) returns (GetMetaResponse);

  // Lock acquires an edit lock on a document.
  rpc Lock(LockRequest) returns (LockResponse);

  // GetSocketToken returns a JWT token for WebSocket streaming.
  rpc GetSocketToken(GetSocketTokenRequest) returns (GetSocketTokenResponse);
}
```

## Making a call - read document

```
curl --location 'http://localhost:1080/twirp/elephant.repository.Documents/Get' \
--header 'Authorization: Bearer eyJhb...m8uKu' \
--header 'Content-Type: application/json' \
--data '{
    "uuid": "142ea73d-dc92-46b8-a546-8e8a870b1d0e",
    "version": 4
}'
```

```
message GetDocumentRequest {
  // UUID of the document to get.
  string uuid = 1;
  // Version to get, omit to get latest (or use status).
  int64 version = 2;
  // Status is used to fetch the version of the document references by the last
  // status update. Can be used instead of specifying a version.
  string status = 3;
  // Lock will lock the document for updates. This only affects the creation of
  // new versions of the document, statuses can still be updated.
  bool lock = 4;
}
```

## Update request

```
message UpdateRequest {
  // UUID of the document to update.
  string uuid = 1;
  // Document version to create.
  Document document = 2;
  // Meta data to associate with the document version.
  map<string, string> meta = 3;
  // IfMatch is used for optimistic locks. Set to the version that you require
  // to be the current one for the update to be performed, or -1 to only perform
  // the update if the document doesn't already exist.
  int64 if_match = 4;
  // Status updates to perform.
  repeated StatusUpdate status  = 5;
  // ACL is an ACL list controlling access to the document.
  repeated ACLEntry acl = 6;
  // ImportDirective can be used to preserve timestamps and authorship
  // information from originating systems, but requires the "doc_import"
  // scope for use.
  ImportDirective import_directive = 7;
}
```

## Making a call - update document

```
curl --location 'http://localhost:1080/twirp/elephant.repository.Documents/Update' \
--header 'Authorization: Bearer eyJhbGciOiJFUzM4NCI...OaY0kfA' \
--header 'Content-Type: application/json' \
--data '{
    "uuid": "142ea73d-dc92-46b8-a546-8e8a870b1d0e",
    "document": {
        "uuid": "142ea73d-dc92-46b8-a546-8e8a870b1d0e",
        "uri": "example://article/2",
        "type": "core/article",
        "title": "Simple docs",
        "content": [
            {
                "type": "core/heading-1",
                "data": {
                    "text": "Simple is better"
                }
            }
        ]
    }
}'
```

## Revisor schema validation

All document writes are validated against the active revisor schemas.

Writing a document with the following content block:

```
{
    "type": "core/heading-1",
    "data": {
        "text": "Simple is better",
        "moar": "better?"
    }
},
```

\...results in:

```
{
    "code": "invalid_argument",
    "msg": "the document had 1 validation errors, the first one is: data attribute \"moar\" [...]",
    "meta": {
        "0": "data attribute \"moar\" of content block 1 (core/heading-1): unknown attribute",
        "err_count": "1"
    }
}

```

## Revisor schema example

Revisor uses block definitions that can be referenced from document declarations:

```
{
  "version": 1,
  "name": "block-example",
  "documents": [
    {
      "name": "Article",
      "description": "An editorial article",
      "declares": "core/article",
      "content": [
        {"ref": "core://text"}
      ]
    }
  ],
  "content": [
    {
      "id": "core://text",
      "block": {
        "description": "A standard text block",
        "declares": {"type":"core/text"},
        "attributes": {
          "role": {
            "optional":true,
            "enum": ["heading-1", "heading-2", "preamble"]
          }
        },
        "data": {
          "text":{
            "allowEmpty":true,
            "format": "html"
          }
        }
      }
    }
  ]
}
```

## Block references

When using `ref` it's possible to extend the block in the same block constraint. Writing this:

```
"meta": [
  {
    "ref": "core://newsvalue",
    "count": 1
  }
]
```

\...is equivalent to:

```
"meta": [
  {"ref": "core://newsvalue"},
  {
    "match": {"type": "core/newsvalue"},
    "count": 1
  }
]
```

Constraints on a ref are treated as a block constraint with a `match` directive equivalent to the `declares` of the referenced block.

## String constraints

```
| Name          | Use                                                                        |
|:--------------|:---------------------------------------------------------------------------|
| optional      | Set to `true` if the value doesn't have to be present                      |
| allowEmpty    | Set to `true` if an empty value is ok                                      |
| const         | A specific `"value"` that must match                                       |
| enum          | A list `["of", "values"]` where one must match                             |
| pattern       | A regular expression that the value must match                             |
| glob          | A list of glob patterns `["http://**", "https://**"]` where one must match |
| format        | A named format that the value must follow                                  |
| time          | A time format specification                                                |
| colourFormats | Controls the "colour" format. Any combination of "hex", "rgb", "rgba"      |
| geometry      | Geometry and coordinate type for WKT strings                               |
| labels        | Labels used to describe the value                                          |
| hints         | Key value pairs used to describe the value                                 |
```

## Formats

The following formats are available:

* `RFC3339`: an RFC3339 timestamp ("2022-05-11T14:10:32Z")
* `int`: an integer ("1234")
* `float`: a floating point number ("12.34")
* `bool`: a boolean ("true" or "false")
* `html`: validate the contents as HTML
* `uuid`: validate the string as a UUID
* `wkt`: validate the string as a WKT geometry
* `colour`: a colour in one of the formats specified in `colourFormats`

When using the format "html" it's also possible to use `htmlPolicy` to use a specific HTML policy.

## Document type variants

Document type variants allow documents to use a suffixed type like `"core/article+template"` and still match the base declaration `"core/article"`. Variants are configured on the validator, not in constraint sets, so that the set of allowed suffixes is controlled by the application.

## Time formats

A Go time parsing layout (see the [time package](https://pkg.go.dev/time#pkg-constants) for documentation) that should be used to validate the timestamp.

## Globs

Glob matching uses [https://github.com/gobwas/glob](https://github.com/gobwas/glob) for matching, and the glob patterns are compiled with "/" and "+" as separators.

```
{
  "match": {"type": {"const":"core/category"}},
  "attributes": {
    "uri": {
      "glob": ["iptc://mediatopic/*"]
    }
  },
  "links": [
    {
      "declares": {"type":"iptc/mediatopic", "rel":"same-as"},
      "attributes": {
        "uri": {
          "glob": ["iptc://mediatopic/*"]
        }
      },
      "data": {
        "id": {"format":"int"}
      }
    }
  ]
}
```

## Status update rules

The repository uses
[https://expr.medv.io/](https://expr.medv.io/) to evaluate rule expressions when you set a status for a document.

This allows for specifying rules for f.ex. publishing `{"AppliesTo": ["usable"], "Types": ["core/article"], "Exp": "..."}`:

```
- Require that published articles have paragraphs:
any(Document.Content, {.Type == "core/paragraph"})

- ...start with a heading:
len(Document.Content) > 0
  and Document.Content[0].Type == "core/heading-1"

- ...that the user has a specific permission:
User.HasScope("publish")

- ...that a reason is given for re-publishing:
Status.ID == 1 or Status.Meta?.reason in ["fix", "correction", "development"]

- ...that the document version has been "approved"
Heads.approved.ID != 0 and Heads.approved.Version == Status.Version

```

## Layering validation

1. Is it a valid document? (typing of the data structure)
2. Is it a valid article? (revisor schema)
3. Does it follow our workflow rules? (status rules)

## The API - Schemas

```
service Schemas {
  // Register a new validation schema version.
  rpc Register(RegisterSchemaRequest) returns (RegisterSchemaResponse);

  // SetActive activates schema versions.
  rpc SetActive(SetActiveSchemaRequest) returns (SetActiveSchemaResponse);

  // Get retrieves a schema.
  rpc Get(GetSchemaRequest) returns (GetSchemaResponse);

  // GetAllActive returns the currently active schemas.
  rpc GetAllActive(GetAllActiveSchemasRequest) returns (GetAllActiveSchemasResponse);

  // ListActive returns the active schema versions.
  rpc ListActive(ListActiveRequest) returns (ListActiveResponse);

  // GetDocumentTypes returns the known document types.
  rpc GetDocumentTypes(GetDocumentTypesRequest) returns (GetDocumentTypesResponse);

  // ConfigureType configures a document type.
  rpc ConfigureType(ConfigureTypeRequest) returns (ConfigureTypeResponse);

  // GetMetaTypes returns registered meta types.
  rpc GetMetaTypes(GetMetaTypesRequest) returns (GetMetaTypesResponse);

  // RegisterMetaType registers a meta document type.
  rpc RegisterMetaType(RegisterMetaTypeRequest) returns (RegisterMetaTypeResponse);

  // GetDeprecations returns deprecation rules.
  rpc GetDeprecations(GetDeprecationsRequest) returns (GetDeprecationsResponse);

  // UpdateDeprecation creates or updates a deprecation rule.
  rpc UpdateDeprecation(UpdateDeprecationRequest) returns (UpdateDeprecationResponse);
}
```

## The API - Workflows

```
service Workflows {
  // UpdateStatus creates or updates a status that can be used for documents.
  rpc UpdateStatus(UpdateStatusRequest) returns (UpdateStatusResponse);

  // GetStatuses lists all enabled statuses.
  rpc GetStatuses(GetStatusesRequest) returns (GetStatusesResponse);

  // CreateStatusRule creates or updates a status rule that should be applied
  // when setting statuses.
  rpc CreateStatusRule(CreateStatusRuleRequest) returns (CreateStatusRuleResponse);

  // DeleteStatusRule removes a status rule.
  rpc DeleteStatusRule(DeleteStatusRuleRequest) returns (DeleteStatusRuleResponse);

  // GetStatusRules returns all status rules.
  rpc GetStatusRules(GetStatusRulesRequest) returns (GetStatusRulesResponse);

  // SetWorkflow creates or updates a workflow definition.
  rpc SetWorkflow(SetWorkflowRequest) returns (SetWorkflowResponse);

  // GetWorkflow retrieves a workflow definition.
  rpc GetWorkflow(GetWorkflowRequest) returns (GetWorkflowResponse);

  // DeleteWorkflow removes a workflow definition.
  rpc DeleteWorkflow(DeleteWorkflowRequest) returns (DeleteWorkflowResponse);
}
```

## The API - Metrics

```
service Metrics {
  // GetMetrics retrieves metric data.
  rpc GetMetrics(GetMetricsRequest) returns (GetMetricsResponse);

  // GetKinds lists registered metric kinds.
  rpc GetKinds(GetKindsRequest) returns (GetKindsResponse);

  // RegisterKind registers a new metric kind.
  rpc RegisterKind(RegisterKindRequest) returns (RegisterKindResponse);

  // DeleteKind deletes a metric kind.
  rpc DeleteKind(DeleteKindRequest) returns (DeleteKindResponse);

  // RegisterMetric registers a metric instance.
  rpc RegisterMetric(RegisterMetricRequest) returns (RegisterMetricResponse);
}
```

## Real-time streaming

Elephant provides two real-time streaming mechanisms:

**Server-Sent Events (SSE)** - Event stream with 200-event replay buffer and topic filtering. Accessible via the `/sse` endpoint. Soon to be deprecated.

**WebSocket** - Per-user rate-limited document and eventlog streaming with JWT socket tokens. Supports:

* Subscribing to document sets by type and timespan
* Subset extraction for partial document delivery
* Including related documents (e.g. deliverables linked from a planning item)
* Eventlog streaming with buffer playback and type-specific subsets

Socket tokens are obtained via `Documents.GetSocketToken` and used to connect to the `/websocket` endpoint.

## Event flow

Mutations -> `event_outbox_item` table -> `EventlogBuilder` processes into `eventlog` -> fans out to SSE/WebSocket/EventBridge.

Internal pub/sub uses `pg.FanOut[T]` backed by PostgreSQL LISTEN/NOTIFY.

## Elephant data mining

Being able to query the full history **and** the contents of documents opens up a lot of potential for generating reports and statistics.

## Publish reasons

```
~# SELECT date(s.created), s.meta->>'cause' AS cause, COUNT(*) AS num
FROM document_status AS s
     INNER JOIN document_version AS v
           ON v.uuid = s.uuid AND v.version = s.version
WHERE s.name='usable' AND s.created >= '2023-02-14' AND s.created < '2023-02-17'
GROUP BY date(s.created), cause ORDER BY date(s.created), cause NULLS FIRST;

    date    |    cause    | num
============+=============+=====
 2023-02-14 |             | 143
 2023-02-14 | correction  |   3
 2023-02-14 | development |  81
 2023-02-14 | fix         |   6
 2023-02-15 |             | 141
 2023-02-15 | correction  |   2
 2023-02-15 | development |  81
 2023-02-15 | fix         |   5
 2023-02-16 |             | 158
 2023-02-16 | correction  |   4
 2023-02-16 | development |  59
 2023-02-16 | fix         |   8
(12 rows)

```

## Time to correction

```
~# SELECT s.uuid, i.created AS initially_published, s.created-i.created AS time_to_correction
FROM document_status AS s
     INNER JOIN document_status AS i
           ON i.uuid = s.uuid AND i.name = s.name AND i.id = 1
WHERE s.name='usable' AND s.meta->>'cause' = 'correction'
ORDER BY s.created;

                 uuid                 |  initially_published   |        time_to_correction
======================================+========================+===================================
 9b2620ec-df55-4091-b7f8-c315182a5b99 | 2023-02-13 12:01:13+00 | @ 1 hour 33 mins 51 secs
 319e8029-769b-4119-8dca-1085d0d49733 | 2023-02-13 14:49:35+00 | @ 46 mins 44 secs
 319e8029-769b-4119-8dca-1085d0d49733 | 2023-02-13 14:49:35+00 | @ 3 hours 11 mins 14 secs
 2c0b198f-77e9-4be5-abe7-1bb32193f38c | 2023-02-14 06:55:26+00 | @ 47 mins 21 secs
 19a52124-c94f-4f21-ab67-27e341ac1304 | 2023-02-14 09:27:13+00 | @ 29 mins 54 secs
 b1eec421-60f4-4fdf-a213-2d6fae395241 | 2023-02-14 12:06:10+00 | @ 3 hours 57 mins 22 secs
 c42afff0-55ea-4efb-80ba-2e3cced3061b | 2023-02-15 04:00:02+00 | @ 2 hours 45 mins 38 secs
 8bacd909-a391-43cd-b1b9-91105ea1d496 | 2023-02-15 15:39:19+00 | @ 4 hours 15 mins 11 secs
 a3657009-c8b4-4310-a5c3-a6600e712b7e | 2023-02-16 02:16:42+00 | @ 8 hours 54 mins 28 secs
 12cd4075-c072-4db1-b677-e7f6ffa8b86d | 2023-02-14 19:01:36+00 | @ 1 day 19 hours 36 mins 22 secs
 9d3a767f-33a6-4527-94fc-39d4c73324b8 | 2023-02-14 05:00:02+00 | @ 2 days 10 hours 17 mins 24 secs
 09ee2a9e-d2a9-4e5e-87fc-4932fc54ba76 | 2023-02-16 19:36:03+00 | @ 15 mins 7 secs
 37969929-40d3-4c30-a9af-db968cb753fd | 2023-02-17 08:58:31+00 | @ 19 mins 18 secs
(13 rows)

```

## High-value articles for a day

```
SELECT vs.section, vs.newsvalue, COUNT(*)
FROM (
     SELECT d.uuid, s.created,
            (jsonb_path_query_first(
                v.document_data,
                '$.meta[*] ? (@.type == "core/newsvalue").data'
            )->>'score')::int AS newsvalue,
            jsonb_path_query_first(
                v.document_data,
                '$.links[*] ? (@.rel == "subject" && @.type == "core/section")'
            )->>'title' AS section
     FROM document_status AS s
          INNER JOIN document AS d ON d.uuid = s.uuid
          INNER JOIN document_version AS v
                ON v.uuid = d.uuid
                   AND v.version = d.current_version
     WHERE
        s.name='usable' AND s.id = 1 AND date(s.created) = '2023-02-14'
) AS vs
WHERE vs.newsvalue <= 2 AND newsvalue > 0
GROUP BY vs.section, vs.newsvalue ORDER BY vs.section, vs.newsvalue;
```

## High-value result

```
 section | newsvalue | count
=========+===========+=======
 Ekonomi |         1 |     3
 Ekonomi |         2 |    11
 Inrikes |         1 |     2
 Inrikes |         2 |    13
 Kultur  |         2 |     2
 Noje    |         2 |     3
 Sport   |         1 |     2
 Sport   |         2 |     7
 Utrikes |         1 |     1
 Utrikes |         2 |    13
(10 rows)
```

## SELECT [...] FOR UPDATE

Throughout elephant `SELECT [...] FOR UPDATE` is used to ensure that only one transaction at a time is acting on a document/object.

* `FOR UPDATE` will block until the transaction can get a write lock on the row(s) being selected.
* `FOR UPDATE SKIP LOCKED` can be used together with `LIMIT` to implement a simple work queue.

The row lock is held until the transaction is committed or rolled back.

## SELECT pg_advisory_xact_lock

`pg_advisory_xact_lock` is used when tasks that can't depend on row locking need to be coordinated, f.ex.:

* Which instance should take responsibility for generating new archive signing keys.

The lock is defined by an integer (`LockSigningKeys` in the code) and is held until the transaction closes.

## Update Concurrency

All updates to a document (new versions, statuses, or ACL changes) start with getting a row lock on the `document` table row for the document. This guarantees that all writes to a documents are serialised.

* Rules out potentially hairy concurrency bugs
* Lets us guarantee that version 1 is followed by 2, 3, 4, and so on
  * ... without any gaps due to failed transactions
* Same thing goes for status IDs

## Documents

A document is represented by one row in the `document` table and 1 or more rows in the `document_version` table.

The `document` table has a reference to the `current_version` that points to the latest version of the document.

Updating a document will add a new row to `document_version` and update the columns `document(updated, updater_uri, current_version)`.

Deleted documents are listed in the `delete_record` table.

## Documents - tables

```sql
create table document(                       create table document_version(
       uuid uuid primary key,                       uuid uuid not null,
       uri text unique not null,                    version bigint not null,
       type text not null,                          created timestamptz not null,
       created timestamptz not null,                creator_uri text not null,
       creator_uri text not null,                   meta jsonb default null,
       updated timestamptz not null,                document_data jsonb,
       updater_uri text not null,                   archived bool not null default false,
       current_version bigint not null,             signature text,
       main_doc uuid,                               language text,
       language text,                               "time" tstzmultirange,
       system_state text,                           labels text[],
       main_doc_type text,                          primary key(uuid, version),
       nonce uuid not null,                         foreign key(uuid) references document(uuid)
       "time" tstzmultirange,                               on delete cascade
       labels text[]                         );
);
```

All tables that carry data for a individual document has a `on delete cascade` reference to the document table. Therefore deleting a row in the document table will remove everything *except* the `delete_records` for the document.

## Statuses

A status ("usable", "approved", "done" et.c.) is always set for a specific version of a document. It does not apply to the `document` as a whole.

Borrowing from git terminology that last status set with a given name is referred to as "head" in elephant. So the currently published version is the one referred to by the current head of "usable".

Statuses cannot be unset, instead a new status should be set that refers to version -1 of the document.

Some statuses that we have today will instead be inferred from the richer status model:

* "replaced" - from the fact that you got a usable status with ID > 1.
* "cancelled" - from the fact that you got a usable status that doesn't refer to a document version.

## Scheduled publishing

Elephant has a `Scheduler` component that handles scheduled publishing:

* Runs as a background service (can be disabled with `--no-scheduler`)
* Monitors documents in a "withheld" workflow state with scheduled publish times
* Automatically transitions documents to "usable" status at the scheduled time
* Uses distributed locking across multiple instances
* Maximum poll interval of 1 minute for discovering new scheduled articles

## Status schema

Each used combination of a document and status name has a row in the `status_heads` table and 1 or more rows in the `document_status` table.

The `status_heads` table has a reference to the `current_id` that points to the latest status of that name that was set for the document.

Just like with document versions, creating a new status will insert a new row into `document_status` and update the columns `status_heads(current_id, updated, updater_uri)`.

## Statuses - tables

```
create table status_heads(                          create table document_status(
       uuid uuid not null,                                 uuid uuid not null,
       name varchar(32) not null,                          name varchar(32) not null,
       current_id bigint not null,                         id bigint not null,
       updated timestamptz not null,                       version bigint not null,
       updater_uri text not null,                          created timestamptz not null,
       type text,                                          creator_uri text not null,
       version bigint,                                     meta jsonb default null,
       language text,                                      archived bool not null default false,
       system_state text,                                  signature text,
       primary key(uuid, name),                            meta_doc_version bigint,
       foreign key(uuid) references document(uuid)         primary key(uuid, name, id),
               on delete cascade                           foreign key(uuid) references document(uuid)
);                                                                 on delete cascade
                                                    );
```

Just like in `document_versions` `document_status` has a `meta jsonb` column that's used to store information about that specific status. A good example would be setting a `{"reason":"correction"}` on a "usable" status.

## Archiving

Each repository instance can run one or more archivers.

* Follows the eventlog and archives the events and its dependent objects.
* Should be the only component that **writes** to S3.

The goal of the archiving process is to have all document data replicated to S3.

This makes it possible to purge old document data from the database (and transparently fetch them if they are requested).

It also enables safe and simple document deletion by retaining copies on S3.

## The signing and archiving process

* Collect all data for the archive object
  * ...for document versions, statuses and events this includes the parent signature
* Serialise the archive object to JSON
* Compute a signature using the hash of the JSON and current signing key
  * `v1.[key ID].[sha256 hash raw url base64].[signature raw url base64]`
* Store the JSON in the archive bucket
  * The signature is set as "X-Amz-Meta-Elephant-Signature" on the object
* Set the `signature`, and `archived` to true for the row

## Deletes

The deletion system ties into the archiving system. The first steps are performed during the delete call handling:

* Get a row lock on the document
* Check if everything related to the document has been archived
  * ...if not, wait until it has.
* Insert a delete record
* Delete the current `document` row (triggering delete cascade)
* Insert a placeholder `document` row where `current_version` refers to the `delete_record` for the delete.

Once this has been done all attempts to update the document, or create a new document with the same UUID, will fail with a "failed_precondition" error code. Reads will yield a "not_found".

## Deletes - Step 2

The archiver reacts to the placeholder document row and starts finalising the delete:

* Get a row lock on the document
* Move all archive objects for the document from `documents/[uuid]/` to `deleted/[uuid]/[delete record id]/`.
* Delete the placeholder row from `documents`.

Now clients are free to create a new document with the same UUID.

## Restore and purge

**Restore** re-creates a deleted document from the S3 archive, preserving its full version history, status history, and authorship information.

**Purge** permanently removes the archived data for a deleted document. This is needed for legal compliance when document data must be fully erased.

Both operations require dedicated permission scopes (`doc_restore` and `doc_purge`).

## Managing ACLs

By default only the user that created a document will have access to it.

This can be changed by supplying an ACL either in the initial or a separate `Update()` call:

```
curl --location 'http://localhost:1080/twirp/elephant.repository.Documents/Update' \
--header 'Authorization: Bearer eyJhbGciO...CxFvmp' \
--header 'Content-Type: application/json' \
--data '{
    "uuid": "142ea73d-dc92-46b8-a546-8e8a870b1d0d",
    "acl": [
        {
            "uri": "core://unit/redaktionen",
            "permissions": [
                "r"
            ]
        }
    ]
}'
```

## Profiling

Run the profiling tool using the `-web` flag and point it to the [PPROF](http://127.0.0.1:1081/debug/pprof/) endpoint:

`go tool pprof -web 'http://127.0.0.1:1081/debug/pprof/profile?seconds=10'`


[![CPU Profile result](static/pprof001.svg)](static/pprof001.svg)


`go tool pprof -web 'http://127.0.0.1:1081/debug/pprof/allocs'`

[![Alloc result](static/pprof002.svg)](static/pprof002.svg)

## Tests

Tests are self-contained and use docker to spin up dependencies like Postgres and Minio (S3-compatible object store):

```
$ go test ./...
?       github.com/ttab/elephant-repository/cmd/repository	[no test files]
?       github.com/ttab/elephant-repository/internal	[no test files]
?       github.com/ttab/elephant-repository/internal/cmd	[no test files]
?       github.com/ttab/elephant-repository/internal/test	[no test files]
?       github.com/ttab/elephant-repository/planning	[no test files]
?       github.com/ttab/elephant-repository/postgres	[no test files]
?       github.com/ttab/elephant-repository/schema	[no test files]
?       github.com/ttab/elephant-repository/sinks	[no test files]
ok      github.com/ttab/elephant-repository/repository	5.642s
```

## Testing the repository

Each individual test creates a new Postgres database and migrates it to the current schema version. A unique bucket for archiving is also created.

It then starts an instance of the repository and returns a test context that can be used to connect to the instance over HTTP.

That way each test gets its own sandbox but re-uses the expensive resources like the postgres and minio containers.

## Test code

```
    res, err := client.Update(ctx, &rpc.UpdateRequest{
        Uuid:     docUUID,
        Document: doc,
    })
    test.Must(t, err, "create article")

    test.Equal(t, 1, res.Version, "expected this to be the first version")

    doc2 := test.CloneMessage(doc)

    doc2.Content = append(doc2.Content, &rpc.Block{
        Type: "core/heading-1",
        Data: map[string]string{
            "text": "The headline of the year",
        },
    })

    res, err = client.Update(ctx, &rpc.UpdateRequest{
        Uuid:     docUUID,
        Document: doc2,
    })
    test.Must(t, err, "update article")
```

## Test flags

Skip the integration tests: `go test -short ./...`

Run a specific test in verbose mode:

```
$ go test -v -run TestIntegrationBasicCrud ./repository
=== RUN   TestIntegrationBasicCrud
    [...]
    api_test.go:51: success: create article
    api_test.go:53: success: expected this to be the first version
    api_test.go:68: success: update article
    api_test.go:70: success: expected this to be the second version
    api_test.go:85: success: expected unknown content block to fail validation: error message: twirp error invalid_argument: the document had 3 validation errors, the first one is: content block 2 (something/made-up): undeclared block type or rel
    api_test.go:90: success: get the document
    api_test.go:92: success: expected the last document to be returned
    api_test.go:99: success: get the first version of the document
    api_test.go:101: success: expected the first document to be returned
    api_test.go:107: success: delete the document
    api_test.go:112: success: expected get to fail after delete: error message: twirp error permission_denied: no read permission for the document
    api_test.go:118: success: expected get of old version to fail after delete: error message: twirp error permission_denied: no read permission for the document
--- PASS: TestIntegrationBasicCrud (5.08s)
PASS
ok      github.com/ttab/elephant-repository/repository	5.090s

```

## SQL query "compilation"

All SQL queries are compiled and type-checked by the [sqlc tool](https://sqlc.dev/).

```
-- name: CheckPermission :one
SELECT (acl.uri IS NOT NULL) = true AS has_access
FROM document AS d
     LEFT JOIN acl
          ON acl.uuid = d.uuid AND acl.uri = ANY(@uri::text[])
          AND @permission::text = ANY(permissions)
WHERE d.uuid = @uuid;
```

Becomes:

```
type CheckPermissionParams struct {
    Uri        pgtype.Array[string]
    Permission string
    Uuid       uuid.UUID
}

func (q *Queries) CheckPermission(
    ctx context.Context, arg CheckPermissionParams,
) (bool, error) {...}
```
