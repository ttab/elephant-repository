# üêò Elephant

Internal 2023-03-07

Hugo Wetterberg
hugo.wetterberg@tt.se

## The repository

The repository is a Go application that exposes a Twirp RPC API.

* Code generation for
  * RPC interfaces and types (from protobuf)
  * SQL queries (from schema and queries)

Still bundled with an "ingester" that can read documents from OC (dawroc) and save them using the document API.

## Running and scaling the Elephant

Except some cached configuration (validation schemas, statuses, et.c.) the service is completely stateless.

* Small footprint
* Redundancy will probably be main reason for running multiple instances
* An instance can run with certain components disabled
  * A dedicated API front instance could run with `--no-archiver --no-replicator --no-reporter`

Where it's necessary to coordinate between instances it's handled by Postgres row locks or advisory locks.

Aims to keep the number of runtime dependencies to a minimum. As long as it gets a Postgres instance and an S3 compatible object store it should "just work".

## The data

Elephant stores:

* documents
* statuses
* ACLs (access control lists)
* document schemas
* archive signing keys
* reporting specifications

All writes go through Postgres so that we get strong consistency guarantees.

A background process called the Archiver continually archives document and status data in S3.

## Immutability

Document versions and statuses are treated as immutable.

Some flags like archived status and signature can be updated, but the actual contents and metadata cannot be changed through the API.

The archiver uses this fact to calculate a signature chain where the entire history of a document can be cryptographically verified.

## The API

The API is defined in a protobuf file.

Elephant exposes four services:

* Documents - for document CRUD operations
* Schemas - for managing Revisor schemas
* Workflows - for managing statuses and status rules
* Reports - for defining periodic reporting

Clients can communicate with these services using JSON or protobuf.

* Generate Twirp clients
* Generate OpenAPI client
* ...or make your own bespoke calls.

## Getting an access token

The API service has an endpoint for fetching dummy tokens for use with the API.

```
curl http://localhost:1080/token \
    -d grant_type=password \
    -d 'username=Hugo Wetterberg <user://tt/hugo, unit://tt/redaktionen>' \
    -d 'scope=doc_read doc_write doc_delete'
```

```
$ curl [...] | jq -r .access_token | awk -F. '{print $2}' | base64 -d | jq .
{
  "iss": "test",
  "sub": "user://tt/hugo",
  "exp": 1677770712,
  "sub_name": "Hugo Wetterberg",
  "scope": "doc_read doc_write doc_delete",
  "units": [
    "unit://tt/redaktionen"
  ]
}
```

It's essentially a password-less password grant where you can specify your own permissions and identity.

## Current permission scopes

* Document CRUD: `doc_read`, `doc_write`, `doc_delete`
  * The doc scopes work together with the document ACLs.
  * Both scope and an ACL granting permission are required.
* `import_directive` allows the caller override timestamps and the user sub for Update requests.
* `workflow_admin` gives access to the `Workflows` service.
* `schema_admin` gives access to the `Schemas` service.
* `reports_admin` gives access to the full `Reports` service.
  * `reports_run` gives access to just `Reports.Run`.

## The API - Documents

```
service Documents {
  // Get retrieves a document version.
  rpc Get(GetDocumentRequest) returns (GetDocumentResponse);

  // GetHistory lists the document version history.
  rpc GetHistory(GetHistoryRequest) returns (GetHistoryResponse);

  // Update is used to create new document versions, set statuses, update ACLs.
  rpc Update(UpdateRequest) returns (UpdateResponse);

  // Validate is used to validate a document without writing it to the
  // repository.
  rpc Validate(ValidateRequest) returns (ValidateResponse);

  // Delete deletes a document and all its associated data.
  rpc Delete(DeleteDocumentRequest) returns (DeleteDocumentResponse);

  // GetMeta returns metadata for a document, including the ACL and current
  // status heads.
  rpc GetMeta(GetMetaRequest) returns (GetMetaResponse);
}
```

## Making a call - read document

```
curl --location 'http://localhost:1080/twirp/elephant.repository.Documents/Get' \
--header 'Authorization: Bearer eyJhb...m8uKu' \
--header 'Content-Type: application/json' \
--data '{
    "uuid": "142ea73d-dc92-46b8-a546-8e8a870b1d0e",
    "version": 4
}'
```

```
message GetDocumentRequest {
  // UUID of the document to get.
  string uuid = 1;
  // Version to get, omit to get latest (or use status).
  int64 version = 2;
  // Status is used to fetch the version of the document references by the last
  // status update. Can be used instead of specifying a version.
  string status = 3;
  // Lock will lock the document for updates. This only affects the creation of
  // new versions of the document, statuses can still be updated.
  bool lock = 4;
}
```

## Update request

```
message UpdateRequest {
  // UUID of the document to update.
  string uuid = 1;
  // Document version to create.
  Document document = 2;
  // Meta data to associate with the document version.
  map<string, string> meta = 3;
  // IfMatch is used for optimistic locks. Set to the version that you require
  // to be the current one for the update to be performed, or -1 to only perform
  // the update if the document doesn't already exist.
  int64 if_match = 4;
  // Status updates to perform.
  repeated StatusUpdate status  = 5;
  // ACL is an ACL list controlling access to the document.
  repeated ACLEntry acl = 6;
  // ImportDirective can be used to preserve timestamps and authorship
  // information from originating systems, but requires the "import_directive"
  // scope for use.
  ImportDirective import_directive = 7;
}
```

## Making a call - update document

```
curl --location 'http://localhost:1080/twirp/elephant.repository.Documents/Update' \
--header 'Authorization: Bearer eyJhbGciOiJFUzM4NCI...OaY0kfA' \
--header 'Content-Type: application/json' \
--data '{
    "uuid": "142ea73d-dc92-46b8-a546-8e8a870b1d0e",
    "document": {
        "uri": "example://article/2",
        "type": "core/article",
        "title": "Simple docs",
        "content": [
            {
                "type": "core/heading-1",
                "data": {
                    "text": "Simple is better"
                }
            }
        ]
    }
}'
```

## Revisor schema validation

All document writes are validated against the active revisor schemas.

Writing a document with the following content block:

```
{
    "type": "core/heading-1",
    "data": {
        "text": "Simple is better",
        "moar": "better?"
    }
},
```

\...results in:

```
{
    "code": "invalid_argument",
    "msg": "the document had 1 validation errors, the first one is: data attribute \"moar\" [...]",
    "meta": {
        "0": "data attribute \"moar\" of content block 1 (core/heading-1): unknown attribute",
        "err_count": "1"
    }
}

```

## Revisor schema example

```
{
  "name": "TT visual element",
  "description": "This can be either a picture or a graphic",
  "declares": {"type":"tt/visual"},
  "data": {
    "caption": {"allowEmpty":true}
  },
  "links": [
    {
      "declares": {"rel":"self"},
      "attributes": {
        "uri": {},
        "url": {},
        "type": {
          "enum": ["tt/picture", "tt/graphic"]
        }
      },
      "data": {
        "credit": {},
        "height": {"format":"int"},
        "width": {"format":"int"},
        "hiresScale": {"format":"float"}
      }
    }]}
```

## String constraints

```
| Name       | Use                                                                                     |
|:-----------|:----------------------------------------------------------------------------------------|
| optional   | Set to `true` if the value doesn't have to be present                                   |
| allowEmpty | Set to `true` if an empty value is ok                                                   |
| const      | A specific `"value"` that must match                                                    |
| enum       | A list `["of", "values"]` where one must match                                          |
| pattern    | A regular expression that the value must match                                          |
| glob       | A list of glob patterns `["http://**", "https://**"]` where one must match              |
| format     | A named format that the value must follow                                               |
| time       | A time format specification                                                             |
```

## Formats

The following formats are available:

* `RFC3339`: an RFC3339 timestamp ("2022-05-11T14:10:32Z")
* `int`: an integer ("1234")
* `float`: a floating point number ("12.34")
* `bool`: a boolean ("true" or "false")
* `html`: validate the contents as HTML

When using the format "html" it's also possible to use `htmlPolicy` to use a specific HTML policy.

## Time formats

A Go time parsing layout (see the [time package](https://pkg.go.dev/time#pkg-constants) for documentation) that should be used to validate the timestamp.

## Globs

Glob matching uses [https://github.com/gobwas/glob](https://github.com/gobwas/glob) for matching, and the glob patterns are compiled with "/" and "+" as separators.

```
{
  "match": {"type": {"const":"core/category"}},
  "attributes": {
    "uri": {
      "glob": ["iptc://mediatopic/*"]
    }
  },
  "links": [
    {
      "declares": {"type":"iptc/mediatopic", "rel":"same-as"},
      "attributes": {
        "uri": {
          "glob": ["iptc://mediatopic/*"]
        }
      },
      "data": {
        "id": {"format":"int"}
      }
    }
  ]
}
```

## Status update rules

The repository uses
[https://expr.medv.io/](https://expr.medv.io/) to evaluate rule expressions when you set a status for a document.

This allows for specifying rules for f.ex. publishing `{"AppliesTo": ["usable"], "Types": ["core/article"], "Exp": "..."}`:

```
- Require that published articles have paragraphs:
any(Document.Content, {.Type == "core/paragraph"})

- ...start with a heading:
len(Document.Content) > 0
  and Document.Content[0].Type == "core/heading-1"

- ...that the user has a specific permission:
User.HasScope("publish")

- ...that a reason is given for re-publishing:
Status.ID == 1 or Status.Meta?.reason in ["fix", "correction", "development"]

- ...that the document version has been "approved"
Heads.approved.ID != 0 and Heads.approved.Version == Status.Version

```

## Layering validation

1. Is it a valid document? (typing of the data structure)
2. Is it a valid article? (revisor schema)
3. Does it follow our workflow rules? (status rules)

## The API - Schemas

```
service Schemas {
  // Register register a new validation schema version.
  rpc Register(RegisterSchemaRequest) returns (RegisterSchemaResponse);

  // SetActive activates schema versions.
  rpc SetActive(SetActiveSchemaRequest) returns (SetActiveSchemaResponse);

  // Get retrieves a schema.
  rpc Get(GetSchemaRequest) returns (GetSchemaResponse);

  // GetAllActiveSchemas returns the currently active schemas.
  rpc GetAllActive(GetAllActiveSchemasRequest) returns (GetAllActiveSchemasResponse);
}
```

## The API - Workflows

```
service Workflows {
  // UpdateStatus creates or updates a status that can be used for documents.
  rpc UpdateStatus(UpdateStatusRequest) returns (UpdateStatusResponse);

  // GetStatuses lists all enabled statuses.
  rpc GetStatuses(GetStatusesRequest) returns (GetStatusesResponse);

  // CreateStatusRule creates or updates a status rule that should be applied
  // when setting statuses.
  rpc CreateStatusRule(CreateStatusRuleRequest) returns (CreateStatusRuleResponse);

  // DeleteStatusRule removes a status rule.
  rpc DeleteStatusRule(DeleteStatusRuleRequest) returns (DeleteStatusRuleResponse);

  // GetStatusRules returns all status rules.
  rpc GetStatusRules(GetStatusRulesRequest) returns (GetStatusRulesResponse);
}
```

## The API - Reports

```
service Reports {
  // Update or create a report.
  rpc Update(UpdateReportRequest) returns (UpdateReportResponse);

  // Get a report.
  rpc Get(GetReportRequest) returns (GetReportResponse);

  // Run a report. This will run the report and return the results instead of
  // sending it to any outputs.
  rpc Run(RunReportRequest) returns (RunReportResponse);
}
```

## Update report request

```
message UpdateReportRequest {
  Report report = 1;
  bool enabled = 2;
}

message Report {                          message ReportQuery {
  string name = 1;                          string name = 1;
  string title = 2;                         repeated int32 summarise = 2;
  bool generate_sheet = 3;                  string sql = 3;
  string cron_expression = 4;               repeated ReportValue value_processing = 4;
  repeated string slack_channels = 5;     }
  repeated ReportQuery queries = 6;
}                                         message ReportValue {
                                            string column = 1;
                                            repeated string processors = 2;
                                          }
```

## Creating a report

```
POST /twirp/elephant.repository.Reports/Update

{
    "report": {
        "name": "last_days",
        "title": "Published last days",
        "cron_expression": "0 7 * * *",
        "queries": [{
            "name": "Published count",
            "sql": "
SELECT to_char(date(created), 'YYYY-MM-DD') AS date, COUNT(*)
FROM document_status WHERE name='usable'
GROUP BY date(created) ORDER BY date(created) DESC LIMIT 7",
            "summarise": [1]
        }]
    },
    "enabled": true
}
```

(SQL string formatted for readability)

## Running a report manually

```
POST /twirp/elephant.repository.Reports/Run

{"name": "last_days"}
```

```
{
    "tables": [
        "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
         ‚îÇ Published count    ‚îÇ
         ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
         ‚îÇ DATE       ‚îÇ COUNT ‚îÇ
         ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
         ‚îÇ 2021-05-29 ‚îÇ   129 ‚îÇ
         ‚îÇ 2021-05-28 ‚îÇ   281 ‚îÇ
         ‚îÇ 2021-05-27 ‚îÇ   303 ‚îÇ
         ‚îÇ 2021-05-26 ‚îÇ   291 ‚îÇ
         ‚îÇ 2021-05-25 ‚îÇ   249 ‚îÇ
         ‚îÇ 2021-05-24 ‚îÇ   262 ‚îÇ
         ‚îÇ 2021-05-23 ‚îÇ   180 ‚îÇ
         ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
         ‚îÇ            ‚îÇ  1695 ‚îÇ
         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò"
    ]
}
```

## Elephant data mining

Being able to query the full history **and** the contents of documents opens up a lot of potential for generating reports and statistics.

## Publish reasons

```
~# SELECT date(s.created), s.meta->>'cause' AS cause, COUNT(*) AS num
FROM document_status AS s
     INNER JOIN document_version AS v
           ON v.uuid = s.uuid AND v.version = s.version
              AND v.type = 'core/article'
WHERE s.name='usable' AND s.created >= '2023-02-14' AND s.created < '2023-02-17'
GROUP BY date(s.created), cause ORDER BY date(s.created), cause NULLS FIRST;

    date    ‚îÇ    cause    ‚îÇ num
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê
 2023-02-14 ‚îÇ ¬§           ‚îÇ 143
 2023-02-14 ‚îÇ correction  ‚îÇ   3
 2023-02-14 ‚îÇ development ‚îÇ  81
 2023-02-14 ‚îÇ fix         ‚îÇ   6
 2023-02-15 ‚îÇ ¬§           ‚îÇ 141
 2023-02-15 ‚îÇ correction  ‚îÇ   2
 2023-02-15 ‚îÇ development ‚îÇ  81
 2023-02-15 ‚îÇ fix         ‚îÇ   5
 2023-02-16 ‚îÇ ¬§           ‚îÇ 158
 2023-02-16 ‚îÇ correction  ‚îÇ   4
 2023-02-16 ‚îÇ development ‚îÇ  59
 2023-02-16 ‚îÇ fix         ‚îÇ   8
(12 rows)

```

## Time to correction

```
~# SELECT s.uuid, i.created AS initially_published, s.created-i.created AS time_to_correction
FROM document_status AS s
     INNER JOIN document_status AS i
           ON i.uuid = s.uuid AND i.name = s.name AND i.id = 1
WHERE s.name='usable' AND s.meta->>'cause' = 'correction'
ORDER BY s.created;

                 uuid                 ‚îÇ  initially_published   ‚îÇ        time_to_correction
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
 9b2620ec-df55-4091-b7f8-c315182a5b99 ‚îÇ 2023-02-13 12:01:13+00 ‚îÇ @ 1 hour 33 mins 51 secs
 319e8029-769b-4119-8dca-1085d0d49733 ‚îÇ 2023-02-13 14:49:35+00 ‚îÇ @ 46 mins 44 secs
 319e8029-769b-4119-8dca-1085d0d49733 ‚îÇ 2023-02-13 14:49:35+00 ‚îÇ @ 3 hours 11 mins 14 secs
 2c0b198f-77e9-4be5-abe7-1bb32193f38c ‚îÇ 2023-02-14 06:55:26+00 ‚îÇ @ 47 mins 21 secs
 19a52124-c94f-4f21-ab67-27e341ac1304 ‚îÇ 2023-02-14 09:27:13+00 ‚îÇ @ 29 mins 54 secs
 b1eec421-60f4-4fdf-a213-2d6fae395241 ‚îÇ 2023-02-14 12:06:10+00 ‚îÇ @ 3 hours 57 mins 22 secs
 c42afff0-55ea-4efb-80ba-2e3cced3061b ‚îÇ 2023-02-15 04:00:02+00 ‚îÇ @ 2 hours 45 mins 38 secs
 8bacd909-a391-43cd-b1b9-91105ea1d496 ‚îÇ 2023-02-15 15:39:19+00 ‚îÇ @ 4 hours 15 mins 11 secs
 a3657009-c8b4-4310-a5c3-a6600e712b7e ‚îÇ 2023-02-16 02:16:42+00 ‚îÇ @ 8 hours 54 mins 28 secs
 12cd4075-c072-4db1-b677-e7f6ffa8b86d ‚îÇ 2023-02-14 19:01:36+00 ‚îÇ @ 1 day 19 hours 36 mins 22 secs
 9d3a767f-33a6-4527-94fc-39d4c73324b8 ‚îÇ 2023-02-14 05:00:02+00 ‚îÇ @ 2 days 10 hours 17 mins 24 secs
 09ee2a9e-d2a9-4e5e-87fc-4932fc54ba76 ‚îÇ 2023-02-16 19:36:03+00 ‚îÇ @ 15 mins 7 secs
 37969929-40d3-4c30-a9af-db968cb753fd ‚îÇ 2023-02-17 08:58:31+00 ‚îÇ @ 19 mins 18 secs
(13 rows)

```

## High-value articles for a day

```
SELECT vs.section, vs.newsvalue, COUNT(*)
FROM (
     SELECT d.uuid, s.created,
            (jsonb_path_query_first(
                v.document_data,
                '$.meta[*] ? (@.type == "core/newsvalue").data'
            )->>'score')::int AS newsvalue,
            jsonb_path_query_first(
                v.document_data,
                '$.links[*] ? (@.rel == "subject" && @.type == "core/section")'
            )->>'title' AS section
     FROM document_status AS s
          INNER JOIN document AS d ON d.uuid = s.uuid
          INNER JOIN document_version AS v
                ON v.uuid = d.uuid
                   AND v.version = d.current_version
                   AND v.type = 'core/article'
     WHERE
        s.name='usable' AND s.id = 1 AND date(s.created) = '2023-02-14'
) AS vs
WHERE vs.newsvalue <= 2 AND newsvalue > 0
GROUP BY vs.section, vs.newsvalue ORDER BY vs.section, vs.newsvalue;
```

## High-value result

```
 section ‚îÇ newsvalue ‚îÇ count
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
 Ekonomi ‚îÇ         1 ‚îÇ     3
 Ekonomi ‚îÇ         2 ‚îÇ    11
 Inrikes ‚îÇ         1 ‚îÇ     2
 Inrikes ‚îÇ         2 ‚îÇ    13
 Kultur  ‚îÇ         2 ‚îÇ     2
 N√∂je    ‚îÇ         2 ‚îÇ     3
 Sport   ‚îÇ         1 ‚îÇ     2
 Sport   ‚îÇ         2 ‚îÇ     7
 Utrikes ‚îÇ         1 ‚îÇ     1
 Utrikes ‚îÇ         2 ‚îÇ    13
(10 rows)
```

## SELECT [...] FOR UPDATE

Throughout elephant `SELECT [...] FOR UPDATE` is used to ensure that only one transaction at a time is acting on a document/object.

* `FOR UPDATE` will block until the transaction can get a write lock on the row(s) being selected.
* `FOR UPDATE SKIP LOCKED` can be used together with `LIMIT` to implement a simple work queue.

The row lock is held until the transaction is committed or rolled back.

## SELECT pg_advisory_xact_lock

`pg_advisory_xact_lock` is used when tasks that can't depend on row locking need to be coordinated, f.ex.:

* Which instance should start the logical replication
* ...or take responsibility for generating new archive signing keys.

The lock is defined by an integer (constants `LockSigningKeys` and
`LockLogicalReplication` in the code) and is held until the transaction closes.

## Update Concurrency

All updates to a document (new versions, statuses, or ACL changes) start with getting a row lock on the `document` table row for the document. This guarantees that all writes to a documents are serialised.

* Rules out potentially hairy concurrency bugs
* Lets us guarantee that version 1 is followed by 2, 3, 4, and so on
  * ... without any gaps due to failed transactions
* Same thing goes for status IDs

## Documents

A document is represented by one row in the `document` table and 1 or more rows in the `document_version` table.

The `document` table has a reference to the `current_version` that points to the latest version of the document.

Updating a document will add a new row to `document_version` and update the columns `document(updated, updater_uri, current_version)`.

Deleted documents are listed in the `delete_record` table.

## Documents - tables

```sql
create table document(                       create table document_version(
       uuid uuid primary key,                       uuid uuid not null,
       uri text unique not null,                    uri text not null,
       created timestamptz not null,                version bigint not null,
       creator_uri text not null,                   title text,
       updated timestamptz not null,                type text not null,
       updater_uri text not null,                   language text,
       current_version bigint not null,             created timestamptz not null,
       deleting bool not null default false         creator_uri text not null,
);                                                  meta jsonb default null,
                                                    document_data jsonb,
                                                    archived bool not null default false,
                                                    signature text,
                                                    primary key(uuid, version),
                                                    foreign key(uuid) references document(uuid)
                                                            on delete cascade
                                             );
```

All tables that carry data for a individual document has a `on delete cascade` reference to the document table. Therefore deleting a row in the document table will remove everything *except* the `delete_records` for the document.

## Notes on the schema

The `document_version` table has a couple of columns (`title`, `uri`, `type`, and `language`) that duplicates data from the `document_data` column. They were created for ease of querying, and everything except `type` should probably be removed.

One thing I'm a bit uncertain of is whether a document should be allowed to change its `type` without an intermediate delete. It feels like something that could cause confusion. In that case it would make sense to move `type` to the `document` table.

## Statuses

A status ("usable", "approved", "done" et.c.) is always set for a specific version of a document. It does not apply to the `document` as a whole.

Borrowing from git terminology that last status set with a given name is referred to as "head" in elephant. So the currently published version is the one referred to by the current head of "usable".

Statuses cannot be unset, instead a new status should be set that refers to version -1 of the document.

Some statuses that we have today will instead be inferred from the richer status model:

* "replaced" - from the fact that you got a usable status with ID > 1.
* "cancelled" - from the fact that you got a usable status that doesn't refer to a document version.

## Status schema

Each used combination of a document and status name has a row in the `status_heads` table and 1 or more rows in the `document_status` table.

The `status_heads` table has a reference to the `current_id` that points to the latest status of that name that was set for the document.

Just like with document versions, creating a new status will insert a new row into `document_status` and update the columns `status_heads(current_id, updated, updater_uri)`.

## Statuses - tables

```
create table status_heads(                          create table document_status(
       uuid uuid not null,                                 uuid uuid not null,
       name varchar(32) not null,                          name varchar(32) not null,
       current_id bigint not null,                         id bigint not null,
       updated timestamptz not null,                       version bigint not null,
       updater_uri text not null,                          created timestamptz not null,
       primary key(uuid, name),                            creator_uri text not null,
       foreign key(uuid) references document(uuid)         meta jsonb default null,
               on delete cascade                           archived bool not null default false,
);                                                         signature text,
                                                           primary key(uuid, name, id),
                                                           foreign key(uuid) references document(uuid)
                                                                   on delete cascade
                                                    );
```

Just like in `document_versions` `document_status` has a `meta jsonb` column that's used to store information about that specific status. A good example would be setting a `{"reason":"correction"}` on a "usable" status for a `R√Ñ`.

## Next steps for statuses

There's a remaining design decision to make about scheduled status changes.

1. Should they be modelled as "withheld" statuses as curently done in OC?
2. Should they be a separate entity altogether, a deferred write op?
3. Should we be able to add future statuses without advancing the head?
4. ...something else?

## Archiving

Each repository instance can run one or more archivers.

* Reacts to changes in the database, not direct calls.
* Should be the only component that **writes** to S3.

The goal of the archiving process is to have all document data replicated to S3.

This will make it possible to purge old document data from the database (and transparently fetch them if they are requested).

It also enables safe and simple document deletion by retaining copies on S3.

## Candidates for archiving

The archiver looks for unarchived document versions and statuses (and soon ACLs through the `acl_audit` table).

```
SELECT
        v.uuid, v.version, v.created, v.creator_uri, v.meta, v.document_data,
        p.signature AS parent_signature
FROM document_version AS v
     LEFT JOIN document_version AS p
          ON p.uuid = v.uuid AND p.version = v.version-1
WHERE v.archived = false
AND (v.version = 1 OR p.archived = true)
ORDER BY v.created
FOR UPDATE OF v SKIP LOCKED
LIMIT 1;
```

This fetches the next unarchived version that either is version 1, or whose parent has been archived, and skips any rows that another archiver is working on.

The reason that we only want versions where the parent has been archived is that we want to include the parent signature in all archive objects.

## The signing and archiving process

* Collect all data for the archive object
  * ...for document versions this includes the parent signature
  * ...for statuses this includes the parent and version signature
* Serialise the archive object to JSON
* Compute a signature using the hash of the JSON and current signing key
  * `v1.[key ID].[sha256 hash raw url base64].[signature raw url base64]`
* Store the JSON in the archive bucket
  * The signature is set as "X-Amz-Meta-Elephant-Signature" on the object
* Set the `signature`, and `archived` to true for the row

## Deletes

The deletion system ties into the archiving system. The first steps are performed during the delete call handling:

* Get a row lock on the document
* Check if everything related to the document has been archived
  * ...if not, wait until it has.
* Insert a delete record
* Delete the current `document` row (triggering delete cascade)
* Insert a placeholder `document` row with `deleting=true`, where `current_version` refers to the `delete_record` for the delete.

Once this has been done all attempts to update the document, or create a new document with the same UUID, will fail with a "failed_precondition" error code. Reads will yield a "not_found".

## Deletes - Step 2

The archiver reacts to the `document` row with `deleting=true` and starts finalising the delete:

* Get a row lock on the document
* Move all archive objects for the document from `documents/[uuid]/` to `deleted/[uuid]/[delete record id]/`.
* Delete the placeholder `deleting=true` row from `documents`.

Now clients are free to create a new document with the same UUID.

## Next steps for deletes

Delete will need a matching restore that re-creates the document and its history. This restoration process should preserve timestamps and authorship information for restored entries.

If we're deleting the document for legal reasons we need to be able to actually purge the document data.

So the next step for deletes should be to add a purge method that will set the delete record to "purge", and let the archiver delete all objects and then finalise the purge by deleting the delete record (or update its status to "purged" or similar).

Just like delete, purge should be gated by a specific permission.

## Managing ACLs

By default only the user that created a document will have access to it.

This can be changed by supplying an ACL either in the initial or a separate `Update()` call:

```
curl --location 'http://localhost:1080/twirp/elephant.repository.Documents/Update' \
--header 'Authorization: Bearer eyJhbGciO...CxFvmp' \
--header 'Content-Type: application/json' \
--data '{
    "uuid": "142ea73d-dc92-46b8-a546-8e8a870b1d0d",
    "acl": [
        {
            "uri": "unit://tt/redaktionen",
            "permissions": [
                "r"
            ]
        }
    ]
}'
```

## Profiling

Run the profiling tool using the `-web` flag and point it to the [PPROF](http://127.0.0.1:1081/debug/pprof/) endpoint:

`go tool pprof -web 'http://127.0.0.1:1081/debug/pprof/profile?seconds=10'`


[![CPU Profile result](static/pprof001.svg)](static/pprof001.svg)


`go tool pprof -web 'http://127.0.0.1:1081/debug/pprof/allocs'`

[![Alloc result](static/pprof002.svg)](static/pprof002.svg)

## Tests

Tests are self-contained and use docker to spin up dependencies like Postgres and Minio (S3-compatible object store):

```
$ go test ./...
?       github.com/ttab/elephant/cmd/docformat	[no test files]
?       github.com/ttab/elephant/cmd/repository	[no test files]
?       github.com/ttab/elephant/cmd/revisor	[no test files]
?       github.com/ttab/elephant/doc	[no test files]
?       github.com/ttab/elephant/ingest	[no test files]
?       github.com/ttab/elephant/internal	[no test files]
?       github.com/ttab/elephant/internal/cmd	[no test files]
?       github.com/ttab/elephant/internal/test	[no test files]
?       github.com/ttab/elephant/postgres	[no test files]
?       github.com/ttab/elephant/rpc/repository	[no test files]
?       github.com/ttab/elephant/schema	[no test files]
ok      github.com/ttab/elephant/repository	5.642s
ok      github.com/ttab/elephant/revisor	(cached)
ok      github.com/ttab/elephant/revisor/constraints	(cached)
```

## Testing the repository

Each individual test creates a new Postgres database and migrates it to the current schema version. A unique bucket for archiving is also created.

It then starts an instance of the repository and returns a test context that can be used to connect to the instance over HTTP.

That way each test gets its own sandbox but re-uses the expensive resources like the postgres and minio containers.

## Test code

```
    res, err := client.Update(ctx, &rpc.UpdateRequest{
        Uuid:     docUUID,
        Document: doc,
    })
    test.Must(t, err, "create article")

    test.Equal(t, 1, res.Version, "expected this to be the first version")

    doc2 := test.CloneMessage(doc)

    doc2.Content = append(doc2.Content, &rpc.Block{
        Type: "core/heading-1",
        Data: map[string]string{
            "text": "The headline of the year",
        },
    })

    res, err = client.Update(ctx, &rpc.UpdateRequest{
        Uuid:     docUUID,
        Document: doc2,
    })
    test.Must(t, err, "update article")
```

## Test flags

Skip the integration tests: `go test -short ./...`

Run a specific test in verbose mode:

```
$ go test -v -run TestIntegrationBasicCrud ./repository
=== RUN   TestIntegrationBasicCrud
    [...]
    api_test.go:51: success: create article
    api_test.go:53: success: expected this to be the first version
    api_test.go:68: success: update article
    api_test.go:70: success: expected this to be the second version
    api_test.go:85: success: expected unknown content block to fail validation: error message: twirp error invalid_argument: the document had 3 validation errors, the first one is: content block 2 (something/made-up): undeclared block type or rel
    api_test.go:90: success: get the document
    api_test.go:92: success: expected the last document to be returned
    api_test.go:99: success: get the first version of the document
    api_test.go:101: success: expected the first document to be returned
    api_test.go:107: success: delete the document
    api_test.go:112: success: expected get to fail after delete: error message: twirp error permission_denied: no read permission for the document
    api_test.go:118: success: expected get of old version to fail after delete: error message: twirp error permission_denied: no read permission for the document
--- PASS: TestIntegrationBasicCrud (5.08s)
PASS
ok      github.com/ttab/elephant/repository	5.090s

```

## SQL query "compilation"

All SQL queries are compiled and type-checked by the [sqlc tool](https://sqlc.dev/).

```
-- name: CheckPermission :one
SELECT (acl.uri IS NOT NULL) = true AS has_access
FROM document AS d
     LEFT JOIN acl
          ON acl.uuid = d.uuid AND acl.uri = ANY(@uri::text[])
          AND @permission::text = ANY(permissions)
WHERE d.uuid = @uuid;
```

Becomes:

```
type CheckPermissionParams struct {
    Uri        pgtype.Array[string]
    Permission string
    Uuid       uuid.UUID
}

func (q *Queries) CheckPermission(
    ctx context.Context, arg CheckPermissionParams,
) (bool, error) {...}
```
